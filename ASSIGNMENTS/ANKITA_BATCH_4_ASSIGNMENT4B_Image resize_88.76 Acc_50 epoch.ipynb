{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANKITA_BATCH_4_ASSIGNMENT4B.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1pFn0wvWOKj93A4_-pjMxsxR96VDyN-NF",
          "timestamp": 1525739732627
        },
        {
          "file_id": "1_1kwmwgL7g94jI6BEtcgm-D2_AFk0zxK",
          "timestamp": 1519101209834
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "bBaZcXRUxjwP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Accuracy : 88.76%\n"
      ]
    },
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from skimage import transform\n",
        "import numpy as np\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "import os as os\n",
        "from google.colab import files\n",
        "import skimage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 40\n",
        "num_filter = 12\n",
        "compression = 2\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8a0a402a-fd62-4fce-81bc-b5b1647ebea9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526492552600,
          "user_tz": -330,
          "elapsed": 62395,
          "user": {
            "displayName": "Ankita Bhagat",
            "photoUrl": "//lh5.googleusercontent.com/-hBbQJG3EmsY/AAAAAAAAAAI/AAAAAAAAEMc/8aZlpsJaxOI/s50-c-k-no/photo.jpg",
            "userId": "106932527741563015055"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "X_train = []\n",
        "X_test = []\n",
        "for i in range(0, x_train.shape[0]):\n",
        "  X_train.append(skimage.transform.resize(x_train[i],(24,24)))\n",
        "\n",
        "X_train = np.asarray(X_train)   \n",
        "  \n",
        "for i in range(0, x_test.shape[0]):\n",
        "  X_test.append(skimage.transform.resize(x_test[i],(24,24)))\n",
        "\n",
        "X_test = np.asarray(X_test)  \n",
        "\n",
        "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], img_height, img_width, channel)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_height, img_width, channel)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255 # Normalise data to [0, 1] range\n",
        "X_test /= 255 # Normalise data to [0, 1] range\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "       \n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "       \n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "   \n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "num_filter = 12\n",
        "dropout_rate = 0.2\n",
        "l = 12  \n",
        "\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "#Conv2D_1_1 = Conv2D(num_filter, (1,1), use_bias=False)(input)\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False)(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "  \n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 10053
        },
        "outputId": "9aac0829-61df-452f-9eeb-926489bdf6a4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526492564504,
          "user_tz": -330,
          "elapsed": 900,
          "user": {
            "displayName": "Ankita Bhagat",
            "photoUrl": "//lh5.googleusercontent.com/-hBbQJG3EmsY/AAAAAAAAAAI/AAAAAAAAEMc/8aZlpsJaxOI/s50-c-k-no/photo.jpg",
            "userId": "106932527741563015055"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 24, 24, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 22, 22, 12)   324         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 22, 22, 12)   48          conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 22, 22, 12)   0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 22, 22, 24)   2592        activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_154 (Dropout)           (None, 22, 22, 24)   0           conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_145 (Concatenate)   (None, 22, 22, 36)   0           conv2d_157[0][0]                 \n",
            "                                                                 dropout_154[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 22, 22, 36)   144         concatenate_145[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 22, 22, 36)   0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 22, 22, 24)   7776        activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_155 (Dropout)           (None, 22, 22, 24)   0           conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_146 (Concatenate)   (None, 22, 22, 60)   0           concatenate_145[0][0]            \n",
            "                                                                 dropout_155[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 22, 22, 60)   240         concatenate_146[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 22, 22, 60)   0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 22, 22, 24)   12960       activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_156 (Dropout)           (None, 22, 22, 24)   0           conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_147 (Concatenate)   (None, 22, 22, 84)   0           concatenate_146[0][0]            \n",
            "                                                                 dropout_156[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 22, 22, 84)   336         concatenate_147[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 22, 22, 84)   0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 22, 22, 24)   18144       activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_157 (Dropout)           (None, 22, 22, 24)   0           conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_148 (Concatenate)   (None, 22, 22, 108)  0           concatenate_147[0][0]            \n",
            "                                                                 dropout_157[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 22, 22, 108)  432         concatenate_148[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 22, 22, 108)  0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 22, 22, 24)   23328       activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_158 (Dropout)           (None, 22, 22, 24)   0           conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_149 (Concatenate)   (None, 22, 22, 132)  0           concatenate_148[0][0]            \n",
            "                                                                 dropout_158[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 22, 22, 132)  528         concatenate_149[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 22, 22, 132)  0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 22, 22, 24)   28512       activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_159 (Dropout)           (None, 22, 22, 24)   0           conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_150 (Concatenate)   (None, 22, 22, 156)  0           concatenate_149[0][0]            \n",
            "                                                                 dropout_159[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 22, 22, 156)  624         concatenate_150[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 22, 22, 156)  0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 22, 22, 24)   33696       activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_160 (Dropout)           (None, 22, 22, 24)   0           conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_151 (Concatenate)   (None, 22, 22, 180)  0           concatenate_150[0][0]            \n",
            "                                                                 dropout_160[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 22, 22, 180)  720         concatenate_151[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 22, 22, 180)  0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 22, 22, 24)   38880       activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_161 (Dropout)           (None, 22, 22, 24)   0           conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_152 (Concatenate)   (None, 22, 22, 204)  0           concatenate_151[0][0]            \n",
            "                                                                 dropout_161[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 22, 22, 204)  816         concatenate_152[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 22, 22, 204)  0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 22, 22, 24)   44064       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_162 (Dropout)           (None, 22, 22, 24)   0           conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_153 (Concatenate)   (None, 22, 22, 228)  0           concatenate_152[0][0]            \n",
            "                                                                 dropout_162[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 22, 22, 228)  912         concatenate_153[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 22, 22, 228)  0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 22, 22, 24)   49248       activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_163 (Dropout)           (None, 22, 22, 24)   0           conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_154 (Concatenate)   (None, 22, 22, 252)  0           concatenate_153[0][0]            \n",
            "                                                                 dropout_163[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 22, 22, 252)  1008        concatenate_154[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 22, 22, 252)  0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 22, 22, 24)   54432       activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_164 (Dropout)           (None, 22, 22, 24)   0           conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_155 (Concatenate)   (None, 22, 22, 276)  0           concatenate_154[0][0]            \n",
            "                                                                 dropout_164[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 22, 22, 276)  1104        concatenate_155[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 22, 22, 276)  0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 22, 22, 24)   59616       activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_165 (Dropout)           (None, 22, 22, 24)   0           conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_156 (Concatenate)   (None, 22, 22, 300)  0           concatenate_155[0][0]            \n",
            "                                                                 dropout_165[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 22, 22, 300)  1200        concatenate_156[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 22, 22, 300)  0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 22, 22, 24)   64800       activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_166 (Dropout)           (None, 22, 22, 24)   0           conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 11, 11, 24)   0           dropout_166[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 11, 11, 24)   96          average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 11, 11, 24)   0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 11, 11, 24)   5184        activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_167 (Dropout)           (None, 11, 11, 24)   0           conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_157 (Concatenate)   (None, 11, 11, 48)   0           average_pooling2d_13[0][0]       \n",
            "                                                                 dropout_167[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 11, 11, 48)   192         concatenate_157[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 11, 11, 48)   0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 11, 11, 24)   10368       activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_168 (Dropout)           (None, 11, 11, 24)   0           conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_158 (Concatenate)   (None, 11, 11, 72)   0           concatenate_157[0][0]            \n",
            "                                                                 dropout_168[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 11, 11, 72)   288         concatenate_158[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 11, 11, 72)   0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 11, 11, 24)   15552       activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_169 (Dropout)           (None, 11, 11, 24)   0           conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_159 (Concatenate)   (None, 11, 11, 96)   0           concatenate_158[0][0]            \n",
            "                                                                 dropout_169[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 11, 11, 96)   384         concatenate_159[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 11, 11, 96)   0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 11, 11, 24)   20736       activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_170 (Dropout)           (None, 11, 11, 24)   0           conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_160 (Concatenate)   (None, 11, 11, 120)  0           concatenate_159[0][0]            \n",
            "                                                                 dropout_170[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 11, 11, 120)  480         concatenate_160[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 11, 11, 120)  0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 11, 11, 24)   25920       activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_171 (Dropout)           (None, 11, 11, 24)   0           conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_161 (Concatenate)   (None, 11, 11, 144)  0           concatenate_160[0][0]            \n",
            "                                                                 dropout_171[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 11, 11, 144)  576         concatenate_161[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 11, 11, 144)  0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 11, 11, 24)   31104       activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_172 (Dropout)           (None, 11, 11, 24)   0           conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_162 (Concatenate)   (None, 11, 11, 168)  0           concatenate_161[0][0]            \n",
            "                                                                 dropout_172[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 11, 11, 168)  672         concatenate_162[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 11, 11, 168)  0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 11, 11, 24)   36288       activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_173 (Dropout)           (None, 11, 11, 24)   0           conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_163 (Concatenate)   (None, 11, 11, 192)  0           concatenate_162[0][0]            \n",
            "                                                                 dropout_173[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 11, 11, 192)  768         concatenate_163[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 11, 11, 192)  0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 11, 11, 24)   41472       activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_174 (Dropout)           (None, 11, 11, 24)   0           conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_164 (Concatenate)   (None, 11, 11, 216)  0           concatenate_163[0][0]            \n",
            "                                                                 dropout_174[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 11, 11, 216)  864         concatenate_164[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 11, 11, 216)  0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 11, 11, 24)   46656       activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_175 (Dropout)           (None, 11, 11, 24)   0           conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_165 (Concatenate)   (None, 11, 11, 240)  0           concatenate_164[0][0]            \n",
            "                                                                 dropout_175[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 11, 11, 240)  960         concatenate_165[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 11, 11, 240)  0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 11, 11, 24)   51840       activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_176 (Dropout)           (None, 11, 11, 24)   0           conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_166 (Concatenate)   (None, 11, 11, 264)  0           concatenate_165[0][0]            \n",
            "                                                                 dropout_176[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 11, 11, 264)  1056        concatenate_166[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 11, 11, 264)  0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 11, 11, 24)   57024       activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_177 (Dropout)           (None, 11, 11, 24)   0           conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_167 (Concatenate)   (None, 11, 11, 288)  0           concatenate_166[0][0]            \n",
            "                                                                 dropout_177[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 11, 11, 288)  1152        concatenate_167[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 11, 11, 288)  0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 11, 11, 24)   62208       activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_178 (Dropout)           (None, 11, 11, 24)   0           conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_168 (Concatenate)   (None, 11, 11, 312)  0           concatenate_167[0][0]            \n",
            "                                                                 dropout_178[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 11, 11, 312)  1248        concatenate_168[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 11, 11, 312)  0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 11, 11, 24)   67392       activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_179 (Dropout)           (None, 11, 11, 24)   0           conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 5, 5, 24)     0           dropout_179[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 5, 5, 24)     96          average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 5, 5, 24)     0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 5, 5, 24)     5184        activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_180 (Dropout)           (None, 5, 5, 24)     0           conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_169 (Concatenate)   (None, 5, 5, 48)     0           average_pooling2d_14[0][0]       \n",
            "                                                                 dropout_180[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 5, 5, 48)     192         concatenate_169[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 5, 5, 48)     0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 5, 5, 24)     10368       activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_181 (Dropout)           (None, 5, 5, 24)     0           conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_170 (Concatenate)   (None, 5, 5, 72)     0           concatenate_169[0][0]            \n",
            "                                                                 dropout_181[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 5, 5, 72)     288         concatenate_170[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 5, 5, 72)     0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 5, 5, 24)     15552       activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_182 (Dropout)           (None, 5, 5, 24)     0           conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_171 (Concatenate)   (None, 5, 5, 96)     0           concatenate_170[0][0]            \n",
            "                                                                 dropout_182[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 5, 5, 96)     384         concatenate_171[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 5, 5, 96)     0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 5, 5, 24)     20736       activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_183 (Dropout)           (None, 5, 5, 24)     0           conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_172 (Concatenate)   (None, 5, 5, 120)    0           concatenate_171[0][0]            \n",
            "                                                                 dropout_183[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 5, 5, 120)    480         concatenate_172[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 5, 5, 120)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 5, 5, 24)     25920       activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_184 (Dropout)           (None, 5, 5, 24)     0           conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_173 (Concatenate)   (None, 5, 5, 144)    0           concatenate_172[0][0]            \n",
            "                                                                 dropout_184[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 5, 5, 144)    576         concatenate_173[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 5, 5, 144)    0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 5, 5, 24)     31104       activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_185 (Dropout)           (None, 5, 5, 24)     0           conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_174 (Concatenate)   (None, 5, 5, 168)    0           concatenate_173[0][0]            \n",
            "                                                                 dropout_185[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 5, 5, 168)    672         concatenate_174[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 5, 5, 168)    0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 5, 5, 24)     36288       activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_186 (Dropout)           (None, 5, 5, 24)     0           conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_175 (Concatenate)   (None, 5, 5, 192)    0           concatenate_174[0][0]            \n",
            "                                                                 dropout_186[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 5, 5, 192)    768         concatenate_175[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 5, 5, 192)    0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 5, 5, 24)     41472       activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_187 (Dropout)           (None, 5, 5, 24)     0           conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_176 (Concatenate)   (None, 5, 5, 216)    0           concatenate_175[0][0]            \n",
            "                                                                 dropout_187[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 5, 5, 216)    864         concatenate_176[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 5, 5, 216)    0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 5, 5, 24)     46656       activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_188 (Dropout)           (None, 5, 5, 24)     0           conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_177 (Concatenate)   (None, 5, 5, 240)    0           concatenate_176[0][0]            \n",
            "                                                                 dropout_188[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 5, 5, 240)    960         concatenate_177[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 5, 5, 240)    0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 5, 5, 24)     51840       activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_189 (Dropout)           (None, 5, 5, 24)     0           conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_178 (Concatenate)   (None, 5, 5, 264)    0           concatenate_177[0][0]            \n",
            "                                                                 dropout_189[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 5, 5, 264)    1056        concatenate_178[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 5, 5, 264)    0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 5, 5, 24)     57024       activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_190 (Dropout)           (None, 5, 5, 24)     0           conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_179 (Concatenate)   (None, 5, 5, 288)    0           concatenate_178[0][0]            \n",
            "                                                                 dropout_190[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 5, 5, 288)    1152        concatenate_179[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 5, 5, 288)    0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 5, 5, 24)     62208       activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_191 (Dropout)           (None, 5, 5, 24)     0           conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_180 (Concatenate)   (None, 5, 5, 312)    0           concatenate_179[0][0]            \n",
            "                                                                 dropout_191[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 5, 5, 312)    1248        concatenate_180[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 5, 5, 312)    0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 5, 5, 24)     67392       activation_195[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_192 (Dropout)           (None, 5, 5, 24)     0           conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 2, 2, 24)     0           dropout_192[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 2, 2, 24)     96          average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 2, 2, 24)     0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 2, 2, 24)     5184        activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_193 (Dropout)           (None, 2, 2, 24)     0           conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_181 (Concatenate)   (None, 2, 2, 48)     0           average_pooling2d_15[0][0]       \n",
            "                                                                 dropout_193[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 2, 2, 48)     192         concatenate_181[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 2, 2, 48)     0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 2, 2, 24)     10368       activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_194 (Dropout)           (None, 2, 2, 24)     0           conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_182 (Concatenate)   (None, 2, 2, 72)     0           concatenate_181[0][0]            \n",
            "                                                                 dropout_194[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 2, 2, 72)     288         concatenate_182[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 2, 2, 72)     0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 2, 2, 24)     15552       activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_195 (Dropout)           (None, 2, 2, 24)     0           conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_183 (Concatenate)   (None, 2, 2, 96)     0           concatenate_182[0][0]            \n",
            "                                                                 dropout_195[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 2, 2, 96)     384         concatenate_183[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 2, 2, 96)     0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 2, 2, 24)     20736       activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_196 (Dropout)           (None, 2, 2, 24)     0           conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_184 (Concatenate)   (None, 2, 2, 120)    0           concatenate_183[0][0]            \n",
            "                                                                 dropout_196[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 2, 2, 120)    480         concatenate_184[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 2, 2, 120)    0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 2, 2, 24)     25920       activation_200[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_197 (Dropout)           (None, 2, 2, 24)     0           conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_185 (Concatenate)   (None, 2, 2, 144)    0           concatenate_184[0][0]            \n",
            "                                                                 dropout_197[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 2, 2, 144)    576         concatenate_185[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 2, 2, 144)    0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 2, 2, 24)     31104       activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_198 (Dropout)           (None, 2, 2, 24)     0           conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_186 (Concatenate)   (None, 2, 2, 168)    0           concatenate_185[0][0]            \n",
            "                                                                 dropout_198[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 2, 2, 168)    672         concatenate_186[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 2, 2, 168)    0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 2, 2, 24)     36288       activation_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_199 (Dropout)           (None, 2, 2, 24)     0           conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_187 (Concatenate)   (None, 2, 2, 192)    0           concatenate_186[0][0]            \n",
            "                                                                 dropout_199[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 2, 2, 192)    768         concatenate_187[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 2, 2, 192)    0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 2, 2, 24)     41472       activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_200 (Dropout)           (None, 2, 2, 24)     0           conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_188 (Concatenate)   (None, 2, 2, 216)    0           concatenate_187[0][0]            \n",
            "                                                                 dropout_200[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 2, 2, 216)    864         concatenate_188[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 2, 2, 216)    0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 2, 2, 24)     46656       activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_201 (Dropout)           (None, 2, 2, 24)     0           conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_189 (Concatenate)   (None, 2, 2, 240)    0           concatenate_188[0][0]            \n",
            "                                                                 dropout_201[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 2, 2, 240)    960         concatenate_189[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 2, 2, 240)    0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 2, 2, 24)     51840       activation_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_202 (Dropout)           (None, 2, 2, 24)     0           conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_190 (Concatenate)   (None, 2, 2, 264)    0           concatenate_189[0][0]            \n",
            "                                                                 dropout_202[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 2, 2, 264)    1056        concatenate_190[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 2, 2, 264)    0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 2, 2, 24)     57024       activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_203 (Dropout)           (None, 2, 2, 24)     0           conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_191 (Concatenate)   (None, 2, 2, 288)    0           concatenate_190[0][0]            \n",
            "                                                                 dropout_203[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 2, 2, 288)    1152        concatenate_191[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 2, 2, 288)    0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 2, 2, 24)     62208       activation_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_204 (Dropout)           (None, 2, 2, 24)     0           conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_192 (Concatenate)   (None, 2, 2, 312)    0           concatenate_191[0][0]            \n",
            "                                                                 dropout_204[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 2, 2, 312)    1248        concatenate_192[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 2, 2, 312)    0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 1, 1, 312)    0           activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 312)          0           average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 10)           3130        flatten_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,823,662\n",
            "Trainable params: 1,806,502\n",
            "Non-trainable params: 17,160\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s_i7ytjrRLjy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# checkpoint\n",
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "logger = CSVLogger(os.path.join(\"LogFile.log\"))\n",
        "callbacks_list = [checkpoint, logger]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1112
        },
        "outputId": "349a5607-5ba7-414d-bb81-287798fb7dc7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526501230402,
          "user_tz": -330,
          "elapsed": 8663913,
          "user": {
            "displayName": "Ankita Bhagat",
            "photoUrl": "//lh5.googleusercontent.com/-hBbQJG3EmsY/AAAAAAAAAAI/AAAAAAAAEMc/8aZlpsJaxOI/s50-c-k-no/photo.jpg",
            "userId": "106932527741563015055"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_test, y_test), \n",
        "                    callbacks = callbacks_list,\n",
        "                    shuffle='True')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "21856/50000 [============>.................] - ETA: 5:29 - loss: 1.8016 - acc: 0.3353"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 590s 12ms/step - loss: 1.5992 - acc: 0.4111 - val_loss: 1.5349 - val_acc: 0.4647\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.46470, saving model to weights.best.hdf5\n",
            "Epoch 2/15\n",
            " 2528/50000 [>.............................] - ETA: 8:59 - loss: 1.3120 - acc: 0.5269"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 1.1664 - acc: 0.5825"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 577s 12ms/step - loss: 1.1665 - acc: 0.5825 - val_loss: 1.3455 - val_acc: 0.5571\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.46470 to 0.55710, saving model to weights.best.hdf5\n",
            "Epoch 3/15\n",
            " 7968/50000 [===>..........................] - ETA: 7:40 - loss: 1.0050 - acc: 0.6344"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.9540 - acc: 0.6605"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 574s 11ms/step - loss: 0.9542 - acc: 0.6604 - val_loss: 1.4039 - val_acc: 0.5927\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.55710 to 0.59270, saving model to weights.best.hdf5\n",
            "Epoch 4/15\n",
            " 7968/50000 [===>..........................] - ETA: 7:26 - loss: 0.8457 - acc: 0.7008"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.8223 - acc: 0.7116"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 568s 11ms/step - loss: 0.8222 - acc: 0.7117 - val_loss: 1.2512 - val_acc: 0.6277\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.59270 to 0.62770, saving model to weights.best.hdf5\n",
            "Epoch 5/15\n",
            " 7968/50000 [===>..........................] - ETA: 7:33 - loss: 0.7679 - acc: 0.7304"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.7392 - acc: 0.7432"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 567s 11ms/step - loss: 0.7393 - acc: 0.7432 - val_loss: 1.0229 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.62770 to 0.69960, saving model to weights.best.hdf5\n",
            "Epoch 6/15\n",
            " 7968/50000 [===>..........................] - ETA: 7:41 - loss: 0.6883 - acc: 0.7626"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.6778 - acc: 0.7640"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 574s 11ms/step - loss: 0.6778 - acc: 0.7640 - val_loss: 0.8225 - val_acc: 0.7272\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.69960 to 0.72720, saving model to weights.best.hdf5\n",
            "Epoch 7/15\n",
            " 7968/50000 [===>..........................] - ETA: 7:41 - loss: 0.6102 - acc: 0.7853"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.6249 - acc: 0.7815"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 573s 11ms/step - loss: 0.6249 - acc: 0.7815 - val_loss: 0.8350 - val_acc: 0.7355\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.72720 to 0.73550, saving model to weights.best.hdf5\n",
            "Epoch 8/15\n",
            " 7968/50000 [===>..........................] - ETA: 7:49 - loss: 0.5689 - acc: 0.8032"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.5807 - acc: 0.8006"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 581s 12ms/step - loss: 0.5806 - acc: 0.8006 - val_loss: 0.7987 - val_acc: 0.7597\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.73550 to 0.75970, saving model to weights.best.hdf5\n",
            "Epoch 9/15\n",
            " 7968/50000 [===>..........................] - ETA: 7:34 - loss: 0.5356 - acc: 0.8179"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.5420 - acc: 0.8128"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 567s 11ms/step - loss: 0.5421 - acc: 0.8127 - val_loss: 0.7712 - val_acc: 0.7642\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.75970 to 0.76420, saving model to weights.best.hdf5\n",
            "Epoch 10/15\n",
            " 7936/50000 [===>..........................] - ETA: 7:38 - loss: 0.5035 - acc: 0.8196"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.5086 - acc: 0.8227"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 570s 11ms/step - loss: 0.5086 - acc: 0.8227 - val_loss: 0.7030 - val_acc: 0.7713\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.76420 to 0.77130, saving model to weights.best.hdf5\n",
            "Epoch 11/15\n",
            " 7936/50000 [===>..........................] - ETA: 7:43 - loss: 0.4625 - acc: 0.8374"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.4774 - acc: 0.8347"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 575s 11ms/step - loss: 0.4774 - acc: 0.8347 - val_loss: 0.6301 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.77130 to 0.80210, saving model to weights.best.hdf5\n",
            "Epoch 12/15\n",
            " 7936/50000 [===>..........................] - ETA: 7:40 - loss: 0.4340 - acc: 0.8463"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.4515 - acc: 0.8439"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 570s 11ms/step - loss: 0.4516 - acc: 0.8438 - val_loss: 0.6659 - val_acc: 0.7950\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80210\n",
            "Epoch 13/15\n",
            " 8832/50000 [====>.........................] - ETA: 7:33 - loss: 0.3998 - acc: 0.8618"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.4277 - acc: 0.8508"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 578s 12ms/step - loss: 0.4277 - acc: 0.8508 - val_loss: 0.6744 - val_acc: 0.7917\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80210\n",
            "Epoch 14/15\n",
            " 8832/50000 [====>.........................] - ETA: 7:35 - loss: 0.3653 - acc: 0.8740"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.3965 - acc: 0.8620"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 579s 12ms/step - loss: 0.3966 - acc: 0.8620 - val_loss: 0.6623 - val_acc: 0.7999\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80210\n",
            "Epoch 15/15\n",
            " 8832/50000 [====>.........................] - ETA: 7:36 - loss: 0.3696 - acc: 0.8696"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.3790 - acc: 0.8683"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 578s 12ms/step - loss: 0.3790 - acc: 0.8683 - val_loss: 0.5543 - val_acc: 0.8285\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.80210 to 0.82850, saving model to weights.best.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1c79ffd7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights('model_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QbUQbG5RikBr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "files.download('model_weights.h5')\n",
        "files.download('LogFile.log')\n",
        "files.download('weights.best.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "loEEQuP_SLJD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "num_filter = 12\n",
        "dropout_rate = 0.2\n",
        "l = 12  \n",
        "\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_height, img_width, channel)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_height, img_width, channel)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255 # Normalise data to [0, 1] range\n",
        "x_test /= 255 # Normalise data to [0, 1] range\n",
        "\n",
        "input1 = Input(shape=(img_height, img_width, channel,))\n",
        "\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False)(input1)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "  \n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output1 = output_layer(Last_Block)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Io3tC14SK_c",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 10053
        },
        "outputId": "c87ed6a7-5ee2-4c88-f44c-d25179172e6c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526501276592,
          "user_tz": -330,
          "elapsed": 807,
          "user": {
            "displayName": "Ankita Bhagat",
            "photoUrl": "//lh5.googleusercontent.com/-hBbQJG3EmsY/AAAAAAAAAAI/AAAAAAAAEMc/8aZlpsJaxOI/s50-c-k-no/photo.jpg",
            "userId": "106932527741563015055"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model1 = Model(inputs=[input1], outputs=[output1])\n",
        "model1.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 30, 30, 12)   324         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 30, 30, 12)   48          conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 30, 30, 12)   0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 30, 30, 24)   2592        activation_209[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_205 (Dropout)           (None, 30, 30, 24)   0           conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_193 (Concatenate)   (None, 30, 30, 36)   0           conv2d_209[0][0]                 \n",
            "                                                                 dropout_205[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 30, 30, 36)   144         concatenate_193[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 30, 30, 36)   0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 30, 30, 24)   7776        activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_206 (Dropout)           (None, 30, 30, 24)   0           conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_194 (Concatenate)   (None, 30, 30, 60)   0           concatenate_193[0][0]            \n",
            "                                                                 dropout_206[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 30, 30, 60)   240         concatenate_194[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 30, 30, 60)   0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 30, 30, 24)   12960       activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_207 (Dropout)           (None, 30, 30, 24)   0           conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_195 (Concatenate)   (None, 30, 30, 84)   0           concatenate_194[0][0]            \n",
            "                                                                 dropout_207[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 30, 30, 84)   336         concatenate_195[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 30, 30, 84)   0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 30, 30, 24)   18144       activation_212[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_208 (Dropout)           (None, 30, 30, 24)   0           conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_196 (Concatenate)   (None, 30, 30, 108)  0           concatenate_195[0][0]            \n",
            "                                                                 dropout_208[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 30, 30, 108)  432         concatenate_196[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 30, 30, 108)  0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 30, 30, 24)   23328       activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_209 (Dropout)           (None, 30, 30, 24)   0           conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_197 (Concatenate)   (None, 30, 30, 132)  0           concatenate_196[0][0]            \n",
            "                                                                 dropout_209[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 30, 30, 132)  528         concatenate_197[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 30, 30, 132)  0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 30, 30, 24)   28512       activation_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_210 (Dropout)           (None, 30, 30, 24)   0           conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_198 (Concatenate)   (None, 30, 30, 156)  0           concatenate_197[0][0]            \n",
            "                                                                 dropout_210[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 30, 30, 156)  624         concatenate_198[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 30, 30, 156)  0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 30, 30, 24)   33696       activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_211 (Dropout)           (None, 30, 30, 24)   0           conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_199 (Concatenate)   (None, 30, 30, 180)  0           concatenate_198[0][0]            \n",
            "                                                                 dropout_211[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 30, 30, 180)  720         concatenate_199[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 30, 30, 180)  0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 30, 30, 24)   38880       activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_212 (Dropout)           (None, 30, 30, 24)   0           conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_200 (Concatenate)   (None, 30, 30, 204)  0           concatenate_199[0][0]            \n",
            "                                                                 dropout_212[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 30, 30, 204)  816         concatenate_200[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 30, 30, 204)  0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 30, 30, 24)   44064       activation_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_213 (Dropout)           (None, 30, 30, 24)   0           conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_201 (Concatenate)   (None, 30, 30, 228)  0           concatenate_200[0][0]            \n",
            "                                                                 dropout_213[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 30, 30, 228)  912         concatenate_201[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 30, 30, 228)  0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 30, 30, 24)   49248       activation_218[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_214 (Dropout)           (None, 30, 30, 24)   0           conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_202 (Concatenate)   (None, 30, 30, 252)  0           concatenate_201[0][0]            \n",
            "                                                                 dropout_214[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 30, 30, 252)  1008        concatenate_202[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 30, 30, 252)  0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 30, 30, 24)   54432       activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_215 (Dropout)           (None, 30, 30, 24)   0           conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_203 (Concatenate)   (None, 30, 30, 276)  0           concatenate_202[0][0]            \n",
            "                                                                 dropout_215[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 30, 30, 276)  1104        concatenate_203[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 30, 30, 276)  0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 30, 30, 24)   59616       activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_216 (Dropout)           (None, 30, 30, 24)   0           conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_204 (Concatenate)   (None, 30, 30, 300)  0           concatenate_203[0][0]            \n",
            "                                                                 dropout_216[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 30, 30, 300)  1200        concatenate_204[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 30, 30, 300)  0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 30, 30, 24)   64800       activation_221[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_217 (Dropout)           (None, 30, 30, 24)   0           conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 15, 15, 24)   0           dropout_217[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 15, 15, 24)   96          average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 15, 15, 24)   0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 15, 15, 24)   5184        activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_218 (Dropout)           (None, 15, 15, 24)   0           conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_205 (Concatenate)   (None, 15, 15, 48)   0           average_pooling2d_17[0][0]       \n",
            "                                                                 dropout_218[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 15, 15, 48)   192         concatenate_205[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 15, 15, 48)   0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 15, 15, 24)   10368       activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_219 (Dropout)           (None, 15, 15, 24)   0           conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_206 (Concatenate)   (None, 15, 15, 72)   0           concatenate_205[0][0]            \n",
            "                                                                 dropout_219[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 15, 15, 72)   288         concatenate_206[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 15, 15, 72)   0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 15, 15, 24)   15552       activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_220 (Dropout)           (None, 15, 15, 24)   0           conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_207 (Concatenate)   (None, 15, 15, 96)   0           concatenate_206[0][0]            \n",
            "                                                                 dropout_220[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 15, 15, 96)   384         concatenate_207[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 15, 15, 96)   0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 15, 15, 24)   20736       activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_221 (Dropout)           (None, 15, 15, 24)   0           conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_208 (Concatenate)   (None, 15, 15, 120)  0           concatenate_207[0][0]            \n",
            "                                                                 dropout_221[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 15, 15, 120)  480         concatenate_208[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 15, 15, 120)  0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 15, 15, 24)   25920       activation_226[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_222 (Dropout)           (None, 15, 15, 24)   0           conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_209 (Concatenate)   (None, 15, 15, 144)  0           concatenate_208[0][0]            \n",
            "                                                                 dropout_222[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 15, 15, 144)  576         concatenate_209[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 15, 15, 144)  0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 15, 15, 24)   31104       activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_223 (Dropout)           (None, 15, 15, 24)   0           conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_210 (Concatenate)   (None, 15, 15, 168)  0           concatenate_209[0][0]            \n",
            "                                                                 dropout_223[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 15, 15, 168)  672         concatenate_210[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 15, 15, 168)  0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 15, 15, 24)   36288       activation_228[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_224 (Dropout)           (None, 15, 15, 24)   0           conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_211 (Concatenate)   (None, 15, 15, 192)  0           concatenate_210[0][0]            \n",
            "                                                                 dropout_224[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 15, 15, 192)  768         concatenate_211[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 15, 15, 192)  0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 15, 15, 24)   41472       activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_225 (Dropout)           (None, 15, 15, 24)   0           conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_212 (Concatenate)   (None, 15, 15, 216)  0           concatenate_211[0][0]            \n",
            "                                                                 dropout_225[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 15, 15, 216)  864         concatenate_212[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 15, 15, 216)  0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 15, 15, 24)   46656       activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_226 (Dropout)           (None, 15, 15, 24)   0           conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_213 (Concatenate)   (None, 15, 15, 240)  0           concatenate_212[0][0]            \n",
            "                                                                 dropout_226[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 15, 15, 240)  960         concatenate_213[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 15, 15, 240)  0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 15, 15, 24)   51840       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_227 (Dropout)           (None, 15, 15, 24)   0           conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_214 (Concatenate)   (None, 15, 15, 264)  0           concatenate_213[0][0]            \n",
            "                                                                 dropout_227[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 15, 15, 264)  1056        concatenate_214[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 15, 15, 264)  0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 15, 15, 24)   57024       activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_228 (Dropout)           (None, 15, 15, 24)   0           conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_215 (Concatenate)   (None, 15, 15, 288)  0           concatenate_214[0][0]            \n",
            "                                                                 dropout_228[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 15, 15, 288)  1152        concatenate_215[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 15, 15, 288)  0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 15, 15, 24)   62208       activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_229 (Dropout)           (None, 15, 15, 24)   0           conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_216 (Concatenate)   (None, 15, 15, 312)  0           concatenate_215[0][0]            \n",
            "                                                                 dropout_229[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 15, 15, 312)  1248        concatenate_216[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 15, 15, 312)  0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 15, 15, 24)   67392       activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_230 (Dropout)           (None, 15, 15, 24)   0           conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 7, 7, 24)     0           dropout_230[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 7, 7, 24)     96          average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 7, 7, 24)     0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 7, 7, 24)     5184        activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_231 (Dropout)           (None, 7, 7, 24)     0           conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_217 (Concatenate)   (None, 7, 7, 48)     0           average_pooling2d_18[0][0]       \n",
            "                                                                 dropout_231[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 7, 7, 48)     192         concatenate_217[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 7, 7, 48)     0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 7, 7, 24)     10368       activation_236[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_232 (Dropout)           (None, 7, 7, 24)     0           conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_218 (Concatenate)   (None, 7, 7, 72)     0           concatenate_217[0][0]            \n",
            "                                                                 dropout_232[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 7, 7, 72)     288         concatenate_218[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 7, 7, 72)     0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 7, 7, 24)     15552       activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_233 (Dropout)           (None, 7, 7, 24)     0           conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_219 (Concatenate)   (None, 7, 7, 96)     0           concatenate_218[0][0]            \n",
            "                                                                 dropout_233[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 7, 7, 96)     384         concatenate_219[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 7, 7, 96)     0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 7, 7, 24)     20736       activation_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_234 (Dropout)           (None, 7, 7, 24)     0           conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_220 (Concatenate)   (None, 7, 7, 120)    0           concatenate_219[0][0]            \n",
            "                                                                 dropout_234[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 7, 7, 120)    480         concatenate_220[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 7, 7, 120)    0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 7, 7, 24)     25920       activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_235 (Dropout)           (None, 7, 7, 24)     0           conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_221 (Concatenate)   (None, 7, 7, 144)    0           concatenate_220[0][0]            \n",
            "                                                                 dropout_235[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 7, 7, 144)    576         concatenate_221[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 7, 7, 144)    0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 7, 7, 24)     31104       activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_236 (Dropout)           (None, 7, 7, 24)     0           conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_222 (Concatenate)   (None, 7, 7, 168)    0           concatenate_221[0][0]            \n",
            "                                                                 dropout_236[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 7, 7, 168)    672         concatenate_222[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 7, 7, 168)    0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 7, 7, 24)     36288       activation_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_237 (Dropout)           (None, 7, 7, 24)     0           conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_223 (Concatenate)   (None, 7, 7, 192)    0           concatenate_222[0][0]            \n",
            "                                                                 dropout_237[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 7, 7, 192)    768         concatenate_223[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 7, 7, 192)    0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 7, 7, 24)     41472       activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_238 (Dropout)           (None, 7, 7, 24)     0           conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_224 (Concatenate)   (None, 7, 7, 216)    0           concatenate_223[0][0]            \n",
            "                                                                 dropout_238[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 7, 7, 216)    864         concatenate_224[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 7, 7, 216)    0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 7, 7, 24)     46656       activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_239 (Dropout)           (None, 7, 7, 24)     0           conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_225 (Concatenate)   (None, 7, 7, 240)    0           concatenate_224[0][0]            \n",
            "                                                                 dropout_239[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 7, 7, 240)    960         concatenate_225[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 7, 7, 240)    0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 7, 7, 24)     51840       activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_240 (Dropout)           (None, 7, 7, 24)     0           conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_226 (Concatenate)   (None, 7, 7, 264)    0           concatenate_225[0][0]            \n",
            "                                                                 dropout_240[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 7, 7, 264)    1056        concatenate_226[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 7, 7, 264)    0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 7, 7, 24)     57024       activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_241 (Dropout)           (None, 7, 7, 24)     0           conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_227 (Concatenate)   (None, 7, 7, 288)    0           concatenate_226[0][0]            \n",
            "                                                                 dropout_241[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 7, 7, 288)    1152        concatenate_227[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 7, 7, 288)    0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 7, 7, 24)     62208       activation_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_242 (Dropout)           (None, 7, 7, 24)     0           conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_228 (Concatenate)   (None, 7, 7, 312)    0           concatenate_227[0][0]            \n",
            "                                                                 dropout_242[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 7, 7, 312)    1248        concatenate_228[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 7, 7, 312)    0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 7, 7, 24)     67392       activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_243 (Dropout)           (None, 7, 7, 24)     0           conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_19 (AveragePo (None, 3, 3, 24)     0           dropout_243[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 3, 3, 24)     96          average_pooling2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 3, 3, 24)     0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 3, 3, 24)     5184        activation_248[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_244 (Dropout)           (None, 3, 3, 24)     0           conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_229 (Concatenate)   (None, 3, 3, 48)     0           average_pooling2d_19[0][0]       \n",
            "                                                                 dropout_244[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 3, 3, 48)     192         concatenate_229[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 3, 3, 48)     0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 3, 3, 24)     10368       activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_245 (Dropout)           (None, 3, 3, 24)     0           conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_230 (Concatenate)   (None, 3, 3, 72)     0           concatenate_229[0][0]            \n",
            "                                                                 dropout_245[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 3, 3, 72)     288         concatenate_230[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 3, 3, 72)     0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 3, 3, 24)     15552       activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_246 (Dropout)           (None, 3, 3, 24)     0           conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_231 (Concatenate)   (None, 3, 3, 96)     0           concatenate_230[0][0]            \n",
            "                                                                 dropout_246[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 3, 3, 96)     384         concatenate_231[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 3, 3, 96)     0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 3, 3, 24)     20736       activation_251[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_247 (Dropout)           (None, 3, 3, 24)     0           conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_232 (Concatenate)   (None, 3, 3, 120)    0           concatenate_231[0][0]            \n",
            "                                                                 dropout_247[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 3, 3, 120)    480         concatenate_232[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 3, 3, 120)    0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 3, 3, 24)     25920       activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_248 (Dropout)           (None, 3, 3, 24)     0           conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_233 (Concatenate)   (None, 3, 3, 144)    0           concatenate_232[0][0]            \n",
            "                                                                 dropout_248[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 3, 3, 144)    576         concatenate_233[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 3, 3, 144)    0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 3, 3, 24)     31104       activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_249 (Dropout)           (None, 3, 3, 24)     0           conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_234 (Concatenate)   (None, 3, 3, 168)    0           concatenate_233[0][0]            \n",
            "                                                                 dropout_249[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 3, 3, 168)    672         concatenate_234[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 3, 3, 168)    0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 3, 3, 24)     36288       activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_250 (Dropout)           (None, 3, 3, 24)     0           conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_235 (Concatenate)   (None, 3, 3, 192)    0           concatenate_234[0][0]            \n",
            "                                                                 dropout_250[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 3, 3, 192)    768         concatenate_235[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 3, 3, 192)    0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 3, 3, 24)     41472       activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_251 (Dropout)           (None, 3, 3, 24)     0           conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_236 (Concatenate)   (None, 3, 3, 216)    0           concatenate_235[0][0]            \n",
            "                                                                 dropout_251[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 3, 3, 216)    864         concatenate_236[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 3, 3, 216)    0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 3, 3, 24)     46656       activation_256[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_252 (Dropout)           (None, 3, 3, 24)     0           conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_237 (Concatenate)   (None, 3, 3, 240)    0           concatenate_236[0][0]            \n",
            "                                                                 dropout_252[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 3, 3, 240)    960         concatenate_237[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 3, 3, 240)    0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 3, 3, 24)     51840       activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_253 (Dropout)           (None, 3, 3, 24)     0           conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_238 (Concatenate)   (None, 3, 3, 264)    0           concatenate_237[0][0]            \n",
            "                                                                 dropout_253[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, 3, 3, 264)    1056        concatenate_238[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 3, 3, 264)    0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 3, 3, 24)     57024       activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_254 (Dropout)           (None, 3, 3, 24)     0           conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_239 (Concatenate)   (None, 3, 3, 288)    0           concatenate_238[0][0]            \n",
            "                                                                 dropout_254[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, 3, 3, 288)    1152        concatenate_239[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 3, 3, 288)    0           batch_normalization_259[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 3, 3, 24)     62208       activation_259[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_255 (Dropout)           (None, 3, 3, 24)     0           conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_240 (Concatenate)   (None, 3, 3, 312)    0           concatenate_239[0][0]            \n",
            "                                                                 dropout_255[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 3, 3, 312)    1248        concatenate_240[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 3, 3, 312)    0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_20 (AveragePo (None, 1, 1, 312)    0           activation_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 312)          0           average_pooling2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10)           3130        flatten_5[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,823,662\n",
            "Trainable params: 1,806,502\n",
            "Non-trainable params: 17,160\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mItTQuB9SKzV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model1.load_weights('model_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ULw92evVSuzG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 2499
        },
        "outputId": "717faa1c-d397-4271-cbe6-6595879b70d9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526521408690,
          "user_tz": -330,
          "elapsed": 20125742,
          "user": {
            "displayName": "Ankita Bhagat",
            "photoUrl": "//lh5.googleusercontent.com/-hBbQJG3EmsY/AAAAAAAAAAI/AAAAAAAAEMc/8aZlpsJaxOI/s50-c-k-no/photo.jpg",
            "userId": "106932527741563015055"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# checkpoint\n",
        "filepath=\"weights.best2.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "logger = CSVLogger(os.path.join(\"LogFile2.log\"))\n",
        "callbacks_list1 = [checkpoint, logger]\n",
        "\n",
        "model1.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=35,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test), \n",
        "                    callbacks = callbacks_list1,\n",
        "                    shuffle='True')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/35\n",
            "21856/50000 [============>.................] - ETA: 5:26 - loss: 0.5136 - acc: 0.8230"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 594s 12ms/step - loss: 0.4682 - acc: 0.8384 - val_loss: 0.4719 - val_acc: 0.8418\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.84180, saving model to weights.best2.hdf5\n",
            "Epoch 2/35\n",
            " 2528/50000 [>.............................] - ETA: 8:43 - loss: 0.3851 - acc: 0.8687"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.3729 - acc: 0.8711"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 578s 12ms/step - loss: 0.3729 - acc: 0.8711 - val_loss: 0.4918 - val_acc: 0.8442\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.84180 to 0.84420, saving model to weights.best2.hdf5\n",
            "Epoch 3/35\n",
            " 7936/50000 [===>..........................] - ETA: 7:40 - loss: 0.3279 - acc: 0.8880"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.3341 - acc: 0.8828"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 574s 11ms/step - loss: 0.3342 - acc: 0.8828 - val_loss: 0.5186 - val_acc: 0.8365\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.84420\n",
            "Epoch 4/35\n",
            " 8864/50000 [====>.........................] - ETA: 7:26 - loss: 0.2829 - acc: 0.9025"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.3021 - acc: 0.8946"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 575s 12ms/step - loss: 0.3021 - acc: 0.8946 - val_loss: 0.5649 - val_acc: 0.8296\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.84420\n",
            "Epoch 5/35\n",
            " 8864/50000 [====>.........................] - ETA: 7:31 - loss: 0.2650 - acc: 0.9052"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.2783 - acc: 0.9023"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 575s 12ms/step - loss: 0.2783 - acc: 0.9023 - val_loss: 0.5621 - val_acc: 0.8317\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.84420\n",
            "Epoch 6/35\n",
            " 8864/50000 [====>.........................] - ETA: 7:28 - loss: 0.2508 - acc: 0.9127"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.2613 - acc: 0.9078"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 575s 12ms/step - loss: 0.2615 - acc: 0.9077 - val_loss: 0.5259 - val_acc: 0.8464\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.84420 to 0.84640, saving model to weights.best2.hdf5\n",
            "Epoch 7/35\n",
            " 7936/50000 [===>..........................] - ETA: 7:41 - loss: 0.2175 - acc: 0.9239"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.2420 - acc: 0.9143"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 575s 11ms/step - loss: 0.2420 - acc: 0.9143 - val_loss: 0.4865 - val_acc: 0.8576\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.84640 to 0.85760, saving model to weights.best2.hdf5\n",
            "Epoch 8/35\n",
            " 7936/50000 [===>..........................] - ETA: 7:38 - loss: 0.2075 - acc: 0.9274"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.2278 - acc: 0.9207"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 574s 11ms/step - loss: 0.2278 - acc: 0.9207 - val_loss: 0.4393 - val_acc: 0.8725\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.85760 to 0.87250, saving model to weights.best2.hdf5\n",
            "Epoch 9/35\n",
            " 7936/50000 [===>..........................] - ETA: 7:38 - loss: 0.1939 - acc: 0.9307"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.2100 - acc: 0.9261"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 573s 11ms/step - loss: 0.2100 - acc: 0.9261 - val_loss: 0.5806 - val_acc: 0.8467\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87250\n",
            "Epoch 10/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:30 - loss: 0.1836 - acc: 0.9357"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1999 - acc: 0.9285"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 577s 12ms/step - loss: 0.1999 - acc: 0.9285 - val_loss: 0.4435 - val_acc: 0.8717\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87250\n",
            "Epoch 11/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:29 - loss: 0.1726 - acc: 0.9380"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1882 - acc: 0.9332"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 574s 11ms/step - loss: 0.1881 - acc: 0.9332 - val_loss: 0.4574 - val_acc: 0.8702\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.87250\n",
            "Epoch 12/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:29 - loss: 0.1668 - acc: 0.9393"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9359"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 574s 11ms/step - loss: 0.1769 - acc: 0.9359 - val_loss: 0.4583 - val_acc: 0.8740\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.87250 to 0.87400, saving model to weights.best2.hdf5\n",
            "Epoch 13/35\n",
            " 7904/50000 [===>..........................] - ETA: 7:36 - loss: 0.1452 - acc: 0.9476"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1674 - acc: 0.9396"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 569s 11ms/step - loss: 0.1674 - acc: 0.9396 - val_loss: 0.4781 - val_acc: 0.8731\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.87400\n",
            "Epoch 14/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:25 - loss: 0.1431 - acc: 0.9486"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1584 - acc: 0.9433"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 569s 11ms/step - loss: 0.1584 - acc: 0.9434 - val_loss: 0.5323 - val_acc: 0.8629\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.87400\n",
            "Epoch 15/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:29 - loss: 0.1371 - acc: 0.9513"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9447"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 569s 11ms/step - loss: 0.1548 - acc: 0.9448 - val_loss: 0.4571 - val_acc: 0.8752\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.87400 to 0.87520, saving model to weights.best2.hdf5\n",
            "Epoch 16/35\n",
            " 7904/50000 [===>..........................] - ETA: 7:35 - loss: 0.1219 - acc: 0.9582"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1431 - acc: 0.9490"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 572s 11ms/step - loss: 0.1432 - acc: 0.9490 - val_loss: 0.4722 - val_acc: 0.8784\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.87520 to 0.87840, saving model to weights.best2.hdf5\n",
            "Epoch 17/35\n",
            " 7904/50000 [===>..........................] - ETA: 7:41 - loss: 0.1119 - acc: 0.9588"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9517"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 574s 11ms/step - loss: 0.1355 - acc: 0.9517 - val_loss: 0.5551 - val_acc: 0.8623\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.87840\n",
            "Epoch 18/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:29 - loss: 0.1265 - acc: 0.9563"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9531"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 573s 11ms/step - loss: 0.1311 - acc: 0.9531 - val_loss: 0.5026 - val_acc: 0.8738\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.87840\n",
            "Epoch 19/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:29 - loss: 0.1160 - acc: 0.9566"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9550"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 575s 11ms/step - loss: 0.1243 - acc: 0.9550 - val_loss: 0.5007 - val_acc: 0.8744\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.87840\n",
            "Epoch 20/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:30 - loss: 0.1022 - acc: 0.9632"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9566"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 576s 12ms/step - loss: 0.1201 - acc: 0.9566 - val_loss: 0.4635 - val_acc: 0.8828\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.87840 to 0.88280, saving model to weights.best2.hdf5\n",
            "Epoch 21/35\n",
            " 7904/50000 [===>..........................] - ETA: 7:40 - loss: 0.0972 - acc: 0.9646"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9580"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 574s 11ms/step - loss: 0.1167 - acc: 0.9580 - val_loss: 0.5372 - val_acc: 0.8656\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.88280\n",
            "Epoch 22/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:30 - loss: 0.1025 - acc: 0.9639"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9603"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 573s 11ms/step - loss: 0.1108 - acc: 0.9603 - val_loss: 0.5161 - val_acc: 0.8790\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.88280\n",
            "Epoch 23/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:28 - loss: 0.0975 - acc: 0.9651"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9618"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 577s 12ms/step - loss: 0.1070 - acc: 0.9619 - val_loss: 0.5684 - val_acc: 0.8663\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.88280\n",
            "Epoch 24/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:33 - loss: 0.0888 - acc: 0.9689"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9628"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 578s 12ms/step - loss: 0.1045 - acc: 0.9628 - val_loss: 0.4822 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.88280 to 0.88390, saving model to weights.best2.hdf5\n",
            "Epoch 25/35\n",
            " 7904/50000 [===>..........................] - ETA: 7:42 - loss: 0.0837 - acc: 0.9715"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9654"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 576s 12ms/step - loss: 0.0991 - acc: 0.9653 - val_loss: 0.5455 - val_acc: 0.8732\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.88390\n",
            "Epoch 26/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:29 - loss: 0.0831 - acc: 0.9712"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9659"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 574s 11ms/step - loss: 0.0964 - acc: 0.9659 - val_loss: 0.4966 - val_acc: 0.8858\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.88390 to 0.88580, saving model to weights.best2.hdf5\n",
            "Epoch 27/35\n",
            " 7904/50000 [===>..........................] - ETA: 7:36 - loss: 0.0773 - acc: 0.9736"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9672"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 571s 11ms/step - loss: 0.0933 - acc: 0.9672 - val_loss: 0.4925 - val_acc: 0.8804\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.88580\n",
            "Epoch 28/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:30 - loss: 0.0812 - acc: 0.9699"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9682"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 577s 12ms/step - loss: 0.0877 - acc: 0.9682 - val_loss: 0.5715 - val_acc: 0.8686\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.88580\n",
            "Epoch 29/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:32 - loss: 0.0840 - acc: 0.9707"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9682"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 575s 12ms/step - loss: 0.0884 - acc: 0.9682 - val_loss: 0.5068 - val_acc: 0.8804\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.88580\n",
            "Epoch 30/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:28 - loss: 0.0754 - acc: 0.9736"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9710"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 573s 11ms/step - loss: 0.0823 - acc: 0.9710 - val_loss: 0.5266 - val_acc: 0.8759\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.88580\n",
            "Epoch 31/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:28 - loss: 0.0796 - acc: 0.9740"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9699"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 573s 11ms/step - loss: 0.0847 - acc: 0.9699 - val_loss: 0.5576 - val_acc: 0.8770\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.88580\n",
            "Epoch 32/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:22 - loss: 0.0767 - acc: 0.9745"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9705"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 569s 11ms/step - loss: 0.0846 - acc: 0.9705 - val_loss: 0.5063 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.88580\n",
            "Epoch 33/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:25 - loss: 0.0640 - acc: 0.9771"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9723"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 563s 11ms/step - loss: 0.0798 - acc: 0.9723 - val_loss: 0.5172 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.88580\n",
            "Epoch 34/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:18 - loss: 0.0739 - acc: 0.9757"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9727"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 559s 11ms/step - loss: 0.0771 - acc: 0.9727 - val_loss: 0.5119 - val_acc: 0.8833\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.88580\n",
            "Epoch 35/35\n",
            " 8832/50000 [====>.........................] - ETA: 7:16 - loss: 0.0742 - acc: 0.9727"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9716"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50000/50000 [==============================] - 561s 11ms/step - loss: 0.0766 - acc: 0.9716 - val_loss: 0.5356 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.88580 to 0.88760, saving model to weights.best2.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1c6fe8f4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "RdRpgUxtEnqK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights('model_weights32.h5')\n",
        "\n",
        "files.download('model_weights32.h5')\n",
        "files.download('LogFile2.log')\n",
        "files.download('weights.best2.hdf5')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jaAxxY5cybrc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model1.load_weights('weights.best2.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1360fdda-86a4-4e6f-aa59-6f94ae45e1c2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526521501213,
          "user_tz": -330,
          "elapsed": 30245,
          "user": {
            "displayName": "Ankita Bhagat",
            "photoUrl": "//lh5.googleusercontent.com/-hBbQJG3EmsY/AAAAAAAAAAI/AAAAAAAAEMc/8aZlpsJaxOI/s50-c-k-no/photo.jpg",
            "userId": "106932527741563015055"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model1.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 30s 3ms/step\n",
            "Test loss: 0.5355630850374699\n",
            "Test accuracy: 0.8876\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}